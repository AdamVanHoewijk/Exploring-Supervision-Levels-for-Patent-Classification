{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_model_evaluation.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Installs and mount drive"],"metadata":{"id":"Dym2PmpxBHSk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqAjX2aoA8aS"},"outputs":[],"source":["%%capture\n","\n","!pip install transformers\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["folder_name = '1_2'\n","num_classes = 2\n","model_name = 'mixtext_model.pt'\n","bert_fine_model_name = 'bert_model.pt'\n","data_eval = 'test.csv'\n","\n","# path folder with models and data\n","PATH = '/content/drive/MyDrive/Masterthesis/MixText/data/' + folder_name + '/'"],"metadata":{"id":"0q3P6JhK5KSX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Method to plot number of patents used vs accuracy"],"metadata":{"id":"Wzd-gL_mKSfR"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","\n","def plot_confidence(probabilities, true):\n","  if not isinstance(probabilities, pd.DataFrame):\n","    probabilities = pd.DataFrame(probabilities)\n","  if not isinstance(true, pd.DataFrame):\n","    true = pd.DataFrame(true)\n","\n","\n","  data_amount = len(true)\n","  acc = []\n","  data_percentage = []\n","  for c in np.arange(0, 1, 0.005):\n","    i = [True if np.max(x) >= c else False for x in probabilities.to_numpy()]\n","    confident_probabilities = probabilities[i]\n","    confident_predictions = np.argmax(confident_probabilities.to_numpy(), axis = 1)+1\n","    confident_true = true[i].T.to_numpy()[0]\n","    accuracy = (confident_predictions == confident_true).mean()\n","    acc.append(accuracy)\n","    data_percentage.append(len(confident_true))\n","\n","  plt.title('Accuracy with uncofident predictions removed')\n","  plt.xlabel('Number of patents included')\n","  plt.ylabel('Accuracy')\n","  plt.plot(data_percentage, acc);\n","  plt.show();"],"metadata":{"id":"qBZs0fX1KRdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Method to evaluate models"],"metadata":{"id":"yZOzoHBngcKh"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","def model_eval(true, probabilities):\n","  pred = np.argmax(probabilities, axis=1) + 1\n","  # create confusion matrix and get accuracy\n","  cf_matrix = confusion_matrix(true, pred)\n","  accuracy  = np.trace(cf_matrix) / float(np.sum(cf_matrix))\n","\n","  # get axis for confusion matrix\n","  labels = []\n","\n","  print(round(f1_score(true, pred, average='macro')*100,1), \"/\", round(f1_score(true, pred, average='micro')*100,1), sep='')\n","\n","  sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels='auto', yticklabels='auto');\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  plt.show()\n","\n","  # accuracy\n","  print('Accuracy: ', accuracy)\n","\n","  #f1 score\n","  print('F1 score macro: ', f1_score(true, pred, average='macro'))\n","  print('F1 score micro: ', f1_score(true, pred, average='micro'))\n","\n","  plot_confidence(probabilities, true)\n"],"metadata":{"id":"iO5JafWugmX5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PATH for evluation"],"metadata":{"id":"uTEh1ThJ5adj"}},{"cell_type":"markdown","source":["# Mixtext model"],"metadata":{"id":"l9k9W3xTBPIz"}},{"cell_type":"code","source":["# redirect to correct file create a MixText model\n","%cd /content/drive/MyDrive/Masterthesis/MixText/code"],"metadata":{"id":"Sjy-Orl5Dqvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from mixtext import MixText\n","\n","# load the saved mixtext model and put it into evaluation mode\n","model = MixText(num_classes, True).cuda()\n","model = nn.DataParallel(model)\n","model.load_state_dict(torch.load(PATH + model_name))\n","model.eval();"],"metadata":{"id":"IYmZ3XjjBT7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","import pandas as pd\n","\n","# create a tokenizer from patent bert\n","tokenizer = AutoTokenizer.from_pretrained('anferico/bert-for-patents', do_lower_case=True)\n","\n","# load the test data for the mixtext model\n","df = pd.read_csv(PATH + data_eval, header=None)\n","df.head()"],"metadata":{"id":"gqCDjw-fk6ub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"id":"LKf3qjr9JORq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[4].value_counts()"],"metadata":{"id":"ZxTpiohWJVO0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Process data to be put into the MixText model"],"metadata":{"id":"RWcJZ4L0CzqR"}},{"cell_type":"code","source":["from keras.preprocessing.sequence import pad_sequences\n","from sys import float_repr_style\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","test_input_ids = []\n","MAX_LEN = 256\n","\n","# tokenize all the patent text\n","for sen in df[2]:\n","  encoded_sent = tokenizer.encode(\n","      str(sen),\n","      add_special_tokens = True,\n","      max_length = MAX_LEN,\n","  )\n","\n","  test_input_ids.append(encoded_sent)\n","\n","# get the true labels\n","test_labels = df[1].to_numpy().astype(int)\n","\n","# pad the sequences so they all are the same length\n","test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN,\n","                               dtype='long', truncating='post', padding='post')\n","\n","# create a attention mask for each text\n","test_attention_masks = []\n","\n","for seq in test_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  test_attention_masks.append(seq_mask)\n","\n","# convert to tensors\n","test_inputs = torch.tensor(test_input_ids)\n","test_masks = torch.tensor(test_attention_masks)\n","test_labels = torch.tensor(test_labels)\n","\n","batch_size = 32\n","\n","# create a dataloader for the test set\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"dl_MNnK8uet9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prediction with MixText model"],"metadata":{"id":"uY3AfHY9C8p9"}},{"cell_type":"code","source":["from scipy.special import softmax\n","import numpy as np\n","\n","# numpy arrays for true labels and the models predictions\n","true_labels = np.array([])\n","probabilities = np.array([])\n","\n","# use a GPU to evaluate\n","device = torch.device('cuda')\n","\n","first_loop = True\n","\n","# get the model to predict\n","for (step, batch) in enumerate(test_dataloader):\n","\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids)\n","\n","  logits = outputs\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  if first_loop:\n","    probabilities = softmax(logits, axis=1)\n","    true_labels = label_ids\n","    first_loop = False\n","  else:\n","    probabilities = np.concatenate((probabilities, softmax(logits, axis=1)))\n","    true_labels = np.concatenate((true_labels, label_ids))"],"metadata":{"id":"PmwJ0vwcX07V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"metadata":{"id":"ZWTknixkxD9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"metadata":{"id":"vhThOqSKxsyG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save predictions and true labels"],"metadata":{"id":"CjGnsdagEdLe"}},{"cell_type":"code","source":["mixtext_pred = np.argmax(probabilities, axis=1) + 1"],"metadata":{"id":"7OQut-V3m3yh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(mixtext_pred == true_labels).mean()"],"metadata":{"id":"dm92MAvK6Goc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation of MixText model"],"metadata":{"id":"_IVdRvXbElNp"}},{"cell_type":"code","source":["model_eval(true_labels, probabilities)\n","len(true_labels)"],"metadata":{"id":"DSti7yJ7Ht9t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tuned BERT"],"metadata":{"id":"t7amp29JSwme"}},{"cell_type":"code","source":["from transformers import BertForSequenceClassification\n","# load the saved mixtext model and put it into evaluation mode\n","'''\n","model = MixText(num_classes, True).cuda()\n","model = nn.DataParallel(model)\n","model.load_state_dict(torch.load(PATH + bert_fine_model_name))\n","model.eval();\n","'''\n","\n","model2 = BertForSequenceClassification.from_pretrained(\n","    'anferico/bert-for-patents',\n","    num_labels = num_classes + 1,\n","    output_attentions = False,\n","    output_hidden_states = False\n",").cuda()\n","model2.load_state_dict(torch.load(PATH + bert_fine_model_name))\n","model2.eval();"],"metadata":{"id":"sehjz9qMS0Uy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a tokenizer from patent bert\n","tokenizer = AutoTokenizer.from_pretrained('anferico/bert-for-patents', do_lower_case=True)\n","\n","# load the test data for the mixtext model\n","df = pd.read_csv(PATH + data_eval, header=None)\n","df.head()"],"metadata":{"id":"voEreCyLT_MR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input_ids = []\n","MAX_LEN = 256\n","\n","# tokenize all the patent text\n","for sen in df[2]:\n","  encoded_sent = tokenizer.encode(\n","      str(sen),\n","      add_special_tokens = True,\n","      max_length = MAX_LEN,\n","  )\n","\n","  test_input_ids.append(encoded_sent)\n","\n","# get the true labels\n","test_labels = df[1].to_numpy().astype(int)\n","\n","# pad the sequences so they all are the same length\n","test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN,\n","                               dtype='long', truncating='post', padding='post')\n","\n","# create a attention mask for each text\n","test_attention_masks = []\n","\n","for seq in test_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  test_attention_masks.append(seq_mask)\n","\n","# convert to tensors\n","test_inputs = torch.tensor(test_input_ids)\n","test_masks = torch.tensor(test_attention_masks)\n","test_labels = torch.tensor(test_labels)\n","\n","batch_size = 32\n","\n","# create a dataloader for the test set\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"98Y-PRo3T32B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.special import softmax\n","import numpy as np\n","\n","# numpy arrays for true labels and the models predictions\n","true_labels_bert = np.array([])\n","guesses_bert = np.array([])\n","\n","# use a GPU to evaluate\n","device = torch.device('cuda')\n","\n","first_loop = True\n","\n","# get the model to predict\n","for (step, batch) in enumerate(test_dataloader):\n","\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","\n","  with torch.no_grad():\n","      outputs = model2(b_input_ids)[0]\n","\n","  logits = outputs\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  if first_loop:\n","    guesses_bert = softmax(logits, axis=1)\n","    true_labels_bert = label_ids\n","    first_loop = False\n","  else:\n","    guesses_bert = np.concatenate((guesses_bert, softmax(logits, axis=1)))\n","    true_labels_bert = np.concatenate((true_labels_bert, label_ids))"],"metadata":{"id":"DCACVRjqTjdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_eval(true_labels_bert, guesses_bert[:,[1,2]])"],"metadata":{"id":"HpKGOFVSZb3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Label MixText model "],"metadata":{"id":"EqCLdhgg8y2I"}},{"cell_type":"code","source":["import pickle\n","\n","# load the model\n","# FIX THE PATH\n","loaded_model = pickle.load(open(PATH + '5_label_model.sav', 'rb'))"],"metadata":{"id":"Z-916QX4gYkP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the labels that can be taken from fixed path because of the later merge on id\n","label_data = pd.read_csv('/content/drive/MyDrive/Masterthesis/data/destilled_and_labels.csv')\n","label_data = label_data.drop_duplicates(subset=['id'])\n","\n","# merge the labels with the test data\n","test_data = pd.read_csv(PATH + data_eval, header = None)\n","test_label_data = pd.merge(test_data, label_data, how = 'left', left_on = [3], right_on = 'id')\n","test_label_data = test_label_data.iloc[:, 14:]"],"metadata":{"id":"Cef8_ppr8e3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_label_data"],"metadata":{"id":"IUHrygoY_hhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get precentages from the models predictions\n","label_proba = loaded_model.predict_proba(test_label_data)"],"metadata":{"id":"_f0NwNcF8e11"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation of Label MixText model"],"metadata":{"id":"tLur7M26h8tN"}},{"cell_type":"code","source":["model_eval(true_labels, label_proba)"],"metadata":{"id":"ZcvGfLUTghIo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Combination of MixText model and Label model"],"metadata":{"id":"Cdejuzo6KmhZ"}},{"cell_type":"markdown","source":["### Evaluation of the combined models"],"metadata":{"id":"W7NHki1NmY2q"}},{"cell_type":"code","source":["model_eval(true_labels, probabilities + label_proba)"],"metadata":{"id":"3qo4IlMjjCyY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Combination of all three models"],"metadata":{"id":"c-v9HBPIMVks"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# open LOTClass prediction probabilities\n","df = pd.read_csv('/content/drive/MyDrive/Masterthesis/LOTClass/datasets/' + folder_name + '/probabilities.csv')\n","\n","results = np.empty((0,2))\n","for index, row in df.iterrows():\n","  results = np.append(results, [[float(row['0'][7:13]), float(row['1'][7:13])]], axis=0)"],"metadata":{"id":"R12AukfyMbKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_eval(true_labels, results)"],"metadata":{"id":"vVaypN4F-2LA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_eval(true_labels, probabilities + label_proba + results)"],"metadata":{"id":"xlDULwz1NjNj"},"execution_count":null,"outputs":[]}]}