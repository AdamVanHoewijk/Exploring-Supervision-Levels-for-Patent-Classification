{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_preprocess_data.ipynb","provenance":[],"collapsed_sections":["-OnaHYEONI02","rW07k2xm0Rqn"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Create dataset"],"metadata":{"id":"bkRFc0YHrbr6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZY28RNtzSREf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ls1VlZ2gFEp"},"outputs":[],"source":["import pandas as pd\n","import re\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","# Import dataset\n","path = '/content/drive/MyDrive/Masterthesis/data/destilled_format.csv'\n","df = pd.read_csv(path)\n","df"]},{"cell_type":"markdown","source":["# Create abstract and description dataset"],"metadata":{"id":"3li5smirlBK7"}},{"cell_type":"code","source":["# Name your new dataset!\n","data_set_name = 'data_2'\n","data_path = '/content/drive/MyDrive/Masterthesis/data/' + data_set_name + '/'\n","\n","if not os.path.isdir(data_path):\n","  os.mkdir(data_path)"],"metadata":{"id":"ojpNHtEL0e6H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataset(df, labels, data_path, idx = None):\n","  # Create new dataframe to save new data t0\n","  data = pd.DataFrame()\n","\n","  # Convert categories to numberic\n","  data['0'] = labels \n","\n","  # Take abstract and fill up with description untill 500 words \n","  N = 500\n","  abst = df['abstract'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","  desc = df['description'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","\n","  text = abst + desc\n","  data['1'] = text.values\n","  data['1'] = data['1'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","  \n","  data['id'] = df['id'].values\n","  data['full_category'] = df['category'].values\n","  if idx != None:\n","    data = data[idx]\n","\n","  # Write to data folder\n","  path = data_path + 'data.csv'\n","  data.to_csv(path, index = False)"],"metadata":{"id":"SiLalWwslNeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataset_2(df, labels, data_path, idx = None):\n","  # Create new dataframe to save new data t0\n","  data = pd.DataFrame()\n","\n","  # Convert categories to numberic\n","  data['0'] = labels \n","\n","  # Take abstract and fill up with description untill 256 words \n","  N = 256\n","  abst = df['title'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","  desc = df['abstract'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","\n","  text = abst + desc\n","  data['1'] = text.values\n","  data['1'] = data['1'].apply(lambda x: str(' '.join(re.split('\\s+', str(x))[:N])))\n","  \n","  data['id'] = df['id'].values\n","  data['full_category'] = df['category'].values\n","  if idx != None:\n","    data = data[idx]\n","\n","  # Write to data folder\n","  path = data_path + 'data.csv'\n","  data.to_csv(path, index = False)"],"metadata":{"id":"fnmGUWQeMyQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset 1_2"],"metadata":{"id":"-OnaHYEONI02"}},{"cell_type":"code","source":["# get first number from category\n","labels = df['category num']\n","\n","# create new idexes for labels\n","labels, index = labels.factorize()\n","labels = pd.Series(labels)\n","\n","# create the dataset\n","create_dataset_2(df, labels, data_path, idx = None)"],"metadata":{"id":"S_TlIT8vNATs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Leaf nodes"],"metadata":{"id":"rW07k2xm0Rqn"}},{"cell_type":"code","source":["# Remove value counts less than 5\n","labels = df['category'].str.replace(r'\\D+', '')\n","counts = labels.value_counts()\n","i = ~labels.isin(counts[counts < 5].index)\n","labels = labels[i]\n","df = df[i]\n","\n","# Create new label number\n","labels, index = labels.factorize()\n","labels = pd.Series(labels)\n","\n","# Save label number assignment\n","pd.Series(index).to_csv(data_path+'label_assignments.csv')\n","\n","# Create the dataset!\n","create_dataset(df, labels, data_path, idx = None)\n","\n","#create_dataset(df, pd.to_numeric(df['category'].str[0])-1, data_path, idx = None)"],"metadata":{"id":"gEo3i_HpyJ9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get first number from category\n","labels = df['category'].str[0]\n","\n","# create new idexes for labels\n","labels, index = labels.factorize()\n","labels = pd.Series(labels)\n","\n","# create the dataset\n","create_dataset(df, labels, data_path, idx = None)"],"metadata":{"id":"DB6oj_-60ffM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The rest"],"metadata":{"id":"EiuCmRGjs3Gq"}},{"cell_type":"code","source":["def create_train_test(data_path):\n","\n","  # Read data\n","  data = pd.read_csv(data_path + 'data.csv')\n","\n","  # Split data\n","  train, test, _, _ = train_test_split(data, data['0'], test_size=0.1, stratify=data['0'], random_state = 42)\n","\n","  # Save data\n","  train.to_csv(data_path + 'train.csv', index = False)\n","  test.to_csv( data_path + 'test.csv', index = False)"],"metadata":{"id":"X7_1xIBNEGy6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_train_test(data_path)"],"metadata":{"id":"4qIGQ_sY07DR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save for LOTClass"],"metadata":{"id":"Celj8PQwkZEX"}},{"cell_type":"code","source":["lotclass_path = '/content/drive/MyDrive/Masterthesis/LOTClass/datasets/'+ data_set_name + '/'\n","\n","if not os.path.isdir(lotclass_path):\n","  os.mkdir(lotclass_path)\n","\n","train = pd.read_csv(data_path + 'train.csv')\n","test = pd.read_csv(data_path + 'test.csv')\n","\n","train['1'].to_csv(lotclass_path + 'train.txt', header=False, index=False)\n","test['1'].to_csv(lotclass_path + 'test.txt', header=False, index=False)\n","test['0'].to_csv(lotclass_path + 'test_labels.txt', header=False, index=False)"],"metadata":{"id":"arJ3bnPylWtf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save for MixText"],"metadata":{"id":"goiY_Nd_Gdei"}},{"cell_type":"code","source":["mixtext_path = '/content/drive/MyDrive/Masterthesis/MixText/data/' + data_set_name + '/'\n","\n","if not os.path.isdir(mixtext_path):\n","  os.mkdir(mixtext_path)\n","\n","train = pd.read_csv(data_path + 'train.csv')\n","test = pd.read_csv(data_path + 'test.csv')\n","\n","# Add one to label to fit MixText standard\n","train['0'] = train['0']+1\n","test['0'] = test['0']+1\n","\n","train['0'] = train['0']\n","train['2'] = train['1']\n","train['1'] = train['0']\n","train = train[['0', '1', '2', 'id',\t'full_category']]\n","\n","test['0'] = test['0']\n","test['2'] = test['1']\n","test['1'] = test['0']\n","test = test[['0', '1', '2', 'id',\t'full_category']]\n","\n","test.to_csv(mixtext_path + 'test.csv', index = None, header=None)\n","train.to_csv(mixtext_path + 'train.csv', index = None, header=None)"],"metadata":{"id":"_vZesrzg1neS"},"execution_count":null,"outputs":[]}]}